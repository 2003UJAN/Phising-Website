{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZLxPxf9gKlxDUAVr2qzq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003UJAN/Phising-Website/blob/main/url_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tldextract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpYQidbUpR9i",
        "outputId": "0d689229-a563-4e77-fecf-e6b29392aab1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tldextract\n",
            "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m71.7/97.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.6)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.31.0)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from requests-file>=1.4->tldextract) (1.16.0)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-1.5.1 tldextract-5.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5P4CcV5vNT3",
        "outputId": "2c1de23b-55e4-40b4-b773-8f5de0ba3af2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dnspython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyNsBy9eFDcL",
        "outputId": "f5b7e178-78f3-4d12-ab25-b8d0607d4b7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dnspython\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/300.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/300.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython\n",
            "Successfully installed dnspython-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-whois"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANbUEDCPX8sj",
        "outputId": "cc5b2991-f135-4292-ffee-f137c6fe9d06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-whois\n",
            "  Downloading python-whois-0.8.0.tar.gz (109 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m81.9/109.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from python-whois) (0.18.3)\n",
            "Building wheels for collected packages: python-whois\n",
            "  Building wheel for python-whois (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-whois: filename=python_whois-0.8.0-py3-none-any.whl size=103246 sha256=6bef129c78321cc31522aa6cc64e8c1fdfb5454d63b60179afb0fea15ac6a3fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/f1/87/145023b9a206e2e948be6480c61ef3fd3dbb81ef11b6977782\n",
            "Successfully built python-whois\n",
            "Installing collected packages: python-whois\n",
            "Successfully installed python-whois-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MVNluFGhdHhT"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from urllib.parse import urlparse,parse_qs\n",
        "import csv\n",
        "from google.colab import files\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import tldextract\n",
        "import socket\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "import dns.resolver\n",
        "import whois\n",
        "import ssl\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "data = pd.read_csv(\"dataset_full.csv\")"
      ],
      "metadata": {
        "id": "fYdbHbrvdRIO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre-processing\n",
        "data = data.drop(data.columns[0], axis=1)\n",
        "data = shuffle(data)\n",
        "threshold = 0.9 * len(data)\n",
        "data = data.dropna(thresh=threshold, axis=1)"
      ],
      "metadata": {
        "id": "kb7ohypBdllW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_row = data.iloc[0]"
      ],
      "metadata": {
        "id": "ou6SgGcmhOXJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(first_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAAsBXXCi8Gb",
        "outputId": "79209e17-a980-4281-dcb2-cf881b9aa441"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qty_hyphen_url          2.0\n",
            "qty_underline_url       0.0\n",
            "qty_slash_url           0.0\n",
            "qty_questionmark_url    0.0\n",
            "qty_equal_url           0.0\n",
            "                       ... \n",
            "qty_redirects           1.0\n",
            "url_google_index        0.0\n",
            "domain_google_index     0.0\n",
            "url_shortened           0.0\n",
            "phishing                0.0\n",
            "Name: 30859, Length: 111, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    'https://www.nitk.ac.in/',\n",
        "    'https://www.meity.gov.in/',\n",
        "    'https://www.srmist.edu.in/'\n",
        "]\n",
        "domain_to_check = 'example.com'\n",
        "ip_address_to_check = '8.8.8.8'\n",
        "hostname_to_check = 'www.example.com'"
      ],
      "metadata": {
        "id": "StH_RCNvkjhn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features={}"
      ],
      "metadata": {
        "id": "Hz2p86drOZqp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_from_url(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path = parsed_url.path\n",
        "\n",
        "    features = {\n",
        "        \"dot\": url.count('.'),\n",
        "        \"hyphen\": url.count('-'),\n",
        "        \"underscore\": url.count('_'),\n",
        "        \"slash\": url.count('/'),\n",
        "        \"question_mark\": url.count('?'),\n",
        "        \"equal\": url.count('='),\n",
        "        \"at\": url.count('@'),\n",
        "        \"ampersand\": url.count('&'),\n",
        "        \"exclamation\": url.count('!'),\n",
        "        \"space\": url.count(' '),\n",
        "        \"tilde\": url.count('~'),\n",
        "        \"comma\": url.count(','),\n",
        "        \"plus\": url.count('+'),\n",
        "        \"asterisk\": url.count('*'),\n",
        "        \"hashtag\": url.count('#'),\n",
        "        \"dollar\": url.count('$'),\n",
        "        \"percent\": url.count('%'),\n",
        "    }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "jlN_avoLmxod"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tld_length(url):\n",
        "    extracted = tldextract.extract(url)\n",
        "    tld_length = len(extracted.suffix)\n",
        "    return tld_length"
      ],
      "metadata": {
        "id": "uBdPjCNvo8tq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_url_length(url):\n",
        "    return len(url)"
      ],
      "metadata": {
        "id": "KlkA0R1IpsLa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_domain_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    features = {\n",
        "        \"dot_domain\": domain.count('.'),\n",
        "        \"hyphen_domain\": domain.count('-'),\n",
        "        \"underscore_domain\": domain.count('_'),\n",
        "        \"slash_domain\": domain.count('/'),\n",
        "        \"questionmark_domain\": domain.count('?'),\n",
        "        \"equal_domain\": domain.count('='),\n",
        "        \"at_domain\": domain.count('@'),\n",
        "        \"and_domain\": domain.count('&'),\n",
        "        \"exclamation_domain\": domain.count('!'),\n",
        "        \"space_domain\": domain.count(' '),\n",
        "        \"tilde_domain\": domain.count('~'),\n",
        "        \"comma_domain\": domain.count(','),\n",
        "        \"plus_domain\": domain.count('+'),\n",
        "        \"asterisk_domain\": domain.count('*'),\n",
        "        \"hashtag_domain\": domain.count('#'),\n",
        "        \"dollar_domain\": domain.count('$'),\n",
        "        \"percent_domain\": domain.count('%'),\n",
        "        \"vowels_domain\": sum(1 for char in domain if char.lower() in 'aeiou')\n",
        "    }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "WjNjCKkPqSYU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_domain_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc  # Extract the domain from the URL\n",
        "\n",
        "    domain_length = len(domain)\n",
        "    return domain_length"
      ],
      "metadata": {
        "id": "cdRooxL-qqGs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_domain_ip(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    try:\n",
        "        ip = socket.gethostbyname(domain)\n",
        "        ip_length = len(ip)\n",
        "        is_ip = True if ip.count('.') == 3 else False\n",
        "\n",
        "        features = {\n",
        "            \"domain_in_ip\": domain in ip,\n",
        "            \"is_ip_address\": is_ip,\n",
        "            \"ip_length\": ip_length,\n",
        "            \"ip\": ip\n",
        "        }\n",
        "    except socket.gaierror:\n",
        "        features = {\n",
        "            \"domain_in_ip\": False,\n",
        "            \"is_ip_address\": False,\n",
        "            \"ip_length\": 0,\n",
        "            \"ip\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "uK1b0OQFrFi7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_server_client_keywords(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc.lower()  # Extract the domain from the URL and convert to lowercase\n",
        "\n",
        "    contains_server = 'server' in domain\n",
        "    contains_client = 'client' in domain\n",
        "\n",
        "    features = {\n",
        "        \"server_in_domain\": contains_server,\n",
        "        \"client_in_domain\": contains_client\n",
        "    }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "-1UL7jfGryM7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_directory_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path  # Extract the path/directory from the URL\n",
        "\n",
        "    features = {\n",
        "        \"dot_directory\": path.count('.'),\n",
        "        \"hyphen_directory\": path.count('-'),\n",
        "        \"underscore_directory\": path.count('_'),\n",
        "        \"slash_directory\": path.count('/'),\n",
        "        \"questionmark_directory\": path.count('?'),\n",
        "        \"equal_directory\": path.count('='),\n",
        "        \"at_directory\": path.count('@'),\n",
        "        \"and_directory\": path.count('&'),\n",
        "        \"exclamation_directory\": path.count('!'),\n",
        "        \"space_directory\": path.count(' '),\n",
        "        \"tilde_directory\": path.count('~'),\n",
        "        \"comma_directory\": path.count(','),\n",
        "        \"plus_directory\": path.count('+'),\n",
        "        \"asterisk_directory\": path.count('*'),\n",
        "        \"hashtag_directory\": path.count('#'),\n",
        "        \"dollar_directory\": path.count('$'),\n",
        "        \"percent_directory\": path.count('%')\n",
        "    }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "6hhWoVIhsF10"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_directory_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path  # Extract the path/directory from the URL\n",
        "\n",
        "    directory_length = len(path)\n",
        "    return directory_length"
      ],
      "metadata": {
        "id": "Rr1PJqdGsVuC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_file_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path\n",
        "    file_name = path.split('/')[-1]\n",
        "\n",
        "    features = {\n",
        "        \"dot_file\": file_name.count('.'),\n",
        "        \"hyphen_file\": file_name.count('-'),\n",
        "        \"underscore_file\": file_name.count('_'),\n",
        "        \"slash_file\": file_name.count('/'),\n",
        "        \"questionmark_file\": file_name.count('?'),\n",
        "        \"equal_file\": file_name.count('='),\n",
        "        \"at_file\": file_name.count('@'),\n",
        "        \"and_file\": file_name.count('&'),\n",
        "        \"exclamation_file\": file_name.count('!'),\n",
        "        \"space_file\": file_name.count(' '),\n",
        "        \"tilde_file\": file_name.count('~'),\n",
        "        \"comma_file\": file_name.count(','),\n",
        "        \"plus_file\": file_name.count('+'),\n",
        "        \"asterisk_file\": file_name.count('*'),\n",
        "        \"hashtag_file\": file_name.count('#'),\n",
        "        \"dollar_file\": file_name.count('$'),\n",
        "        \"percent_file\": file_name.count('%')\n",
        "    }\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "pC29gI2TsmHN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_file_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path\n",
        "\n",
        "    file_name = path.split('/')[-1]\n",
        "\n",
        "    file_length = len(file_name)\n",
        "    return file_length"
      ],
      "metadata": {
        "id": "4yxJJBlys3ac"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_params_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    query = parsed_url.query\n",
        "    parsed_query = parse_qs(query)\n",
        "\n",
        "    params_str = '&'.join([','.join(v) for v in parsed_query.values()])\n",
        "\n",
        "    features = {\n",
        "        \"dot_params\": params_str.count('.'),\n",
        "        \"hyphen_params\": params_str.count('-'),\n",
        "        \"underscore_params\": params_str.count('_'),\n",
        "        \"slash_params\": params_str.count('/'),\n",
        "        \"questionmark_params\": params_str.count('?'),\n",
        "        \"equal_params\": params_str.count('='),\n",
        "        \"at_params\": params_str.count('@'),\n",
        "        \"and_params\": params_str.count('&'),\n",
        "        \"exclamation_params\": params_str.count('!'),\n",
        "        \"space_params\": params_str.count(' '),\n",
        "        \"tilde_params\": params_str.count('~'),\n",
        "        \"comma_params\": params_str.count(','),\n",
        "        \"plus_params\": params_str.count('+'),\n",
        "        \"asterisk_params\": params_str.count('*'),\n",
        "        \"hashtag_params\": params_str.count('#'),\n",
        "        \"dollar_params\": params_str.count('$'),\n",
        "        \"percent_params\": params_str.count('%')\n",
        "    }\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "y9MC7_dTtSLH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_params_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    query = parsed_url.query\n",
        "\n",
        "    params_length = len(query)\n",
        "    return params_length"
      ],
      "metadata": {
        "id": "CLn-UuDxtt4O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tld_present_in_params(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    query_params = parsed_url.query\n",
        "\n",
        "    tld = tldextract.extract(url).suffix\n",
        "\n",
        "    parsed_query = parse_qs(query_params)\n",
        "\n",
        "    tld_present = any(tld in value for values in parsed_query.values() for value in values)\n",
        "\n",
        "    return tld_present"
      ],
      "metadata": {
        "id": "4cz0K-4HuQbp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    query_params = parsed_url.query\n",
        "\n",
        "    parsed_query = parse_qs(query_params)\n",
        "\n",
        "    num_params = sum(len(values) for values in parsed_query.values())\n",
        "\n",
        "    return num_params"
      ],
      "metadata": {
        "id": "wpouq48kuhGb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def email_in_url(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_string = parsed_url.geturl()\n",
        "\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "\n",
        "    match = re.search(email_pattern, url_string)\n",
        "\n",
        "    return bool(match)\n"
      ],
      "metadata": {
        "id": "ynm1ARJOu1Zl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_response(url):\n",
        "  parsed_url = urlparse(url)\n",
        "  domain = parsed_url.netloc\n",
        "  start_time = time.time()\n",
        "  response = requests.get(url)\n",
        "  end_time = time.time()\n",
        "  response_time = end_time - start_time\n",
        "  return response_time"
      ],
      "metadata": {
        "id": "YtSiIq0FvDrc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_spf_record(domain):\n",
        "    try:\n",
        "        answers = dns.resolver.resolve(domain, 'TXT')\n",
        "        for rdata in answers:\n",
        "            if 'v=spf1' in rdata.to_text():\n",
        "                return True\n",
        "        return False\n",
        "    except dns.resolver.NoAnswer:\n",
        "        return False\n",
        "    except dns.resolver.NXDOMAIN:\n",
        "        return False\n",
        "    except dns.resolver.NoNameservers:\n",
        "        return False"
      ],
      "metadata": {
        "id": "J-FciUJlCuDp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_asn_info(ip_address):\n",
        "    # Replace 'YOUR_TOKEN' with your IPinfo API token\n",
        "    token = 'YOUR_TOKEN'\n",
        "    url = f'https://ipinfo.io/{ip_address}/json?token={token}'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if 'asn' in data:\n",
        "                return data['asn']\n",
        "            else:\n",
        "                return \"ASN information not found.\"\n",
        "        else:\n",
        "            return \"Request failed.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Request error: {e}\""
      ],
      "metadata": {
        "id": "oPLppWZFvD7t"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_domain_dates(domain_name):\n",
        "    try:\n",
        "        domain = whois.whois(domain_name)\n",
        "\n",
        "        # Extract creation and expiration dates\n",
        "        creation_date = domain.creation_date\n",
        "        expiration_date = domain.expiration_date\n",
        "\n",
        "        # Calculate time differences\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        if isinstance(expiration_date, list):\n",
        "            expiration_date = expiration_date[0]\n",
        "\n",
        "        # Calculate days until expiration\n",
        "        if creation_date and expiration_date:\n",
        "            current_time = datetime.now()\n",
        "            activation_time = (current_time - creation_date).days\n",
        "            expiration_time = (expiration_date - current_time).days\n",
        "\n",
        "            return activation_time, expiration_time\n",
        "        else:\n",
        "            return None, None\n",
        "    except whois.parser.PywhoisError as e:\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "VdzmlTjavEFW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_qty_resolved_ips(domain):\n",
        "    try:\n",
        "        ips = socket.getaddrinfo(domain, None)\n",
        "        return len(set(ip[4][0] for ip in ips))\n",
        "    except socket.gaierror:\n",
        "        return 0\n",
        "\n",
        "def get_qty_nameservers(domain):\n",
        "    try:\n",
        "        ns_records = dns.resolver.resolve(domain, 'NS')\n",
        "        return len(ns_records)\n",
        "    except (dns.resolver.NoAnswer, dns.resolver.NXDOMAIN):\n",
        "        return 0\n",
        "\n",
        "def get_qty_mx_servers(domain):\n",
        "    try:\n",
        "        mx_records = dns.resolver.resolve(domain, 'MX')\n",
        "        return len(mx_records)\n",
        "    except (dns.resolver.NoAnswer, dns.resolver.NXDOMAIN):\n",
        "        return 0"
      ],
      "metadata": {
        "id": "ibrw743nvEO9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hostname_ttl(hostname):\n",
        "    try:\n",
        "        ip_addresses = socket.gethostbyname_ex(hostname)\n",
        "        if len(ip_addresses) > 2:\n",
        "            # Get the TTL from the first IP address entry\n",
        "            ttl = ip_addresses[2][0].ttl\n",
        "            return ttl\n",
        "        else:\n",
        "            return None\n",
        "    except socket.gaierror:\n",
        "        return None"
      ],
      "metadata": {
        "id": "HU7-wgO4YNBQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_redirect_count(url):\n",
        "    try:\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "        return len(response.history)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return 0"
      ],
      "metadata": {
        "id": "g_rYfP8YYNXy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_url_indexing(url):\n",
        "    try:\n",
        "        response = requests.get(f\"https://www.google.com/search?q=site:{url}\")\n",
        "        return 'did not match any documents' not in response.text\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "Rn4pmZUgYNyC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_domain_indexing(domain):\n",
        "    try:\n",
        "        response = requests.get(f\"https://www.google.com/search?q=site:{domain}\")\n",
        "        return 'did not match any documents' not in response.text\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "f63Fc6jNay-g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_url_shortened(url):\n",
        "    length_threshold = 0.6\n",
        "    original_length = len(url)\n",
        "    if original_length < 25:\n",
        "        return False\n",
        "    else:\n",
        "        return len(url) <= length_threshold * original_length"
      ],
      "metadata": {
        "id": "wIrJ_9a0bq_0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for url in urls:\n",
        "    url_features = extract_features_from_url(url)\n",
        "    print(f\"URL: {url}\")\n",
        "    print(url_features)\n",
        "    tld_length = extract_tld_length(url)\n",
        "    print(f\"TLD Length: {tld_length}\")\n",
        "    url_length = extract_url_length(url)\n",
        "    print(f\"URL Length: {url_length}\")\n",
        "    domain_features = extract_domain_features(url)\n",
        "    print(domain_features)\n",
        "    length = extract_domain_length(url)\n",
        "    print(f\"Domain Length: {length}\")\n",
        "    ip_features = extract_domain_ip(url)\n",
        "    print(ip_features)\n",
        "    server_client_features = extract_server_client_keywords(url)\n",
        "    print(server_client_features)\n",
        "    directory_features = extract_directory_features(url)\n",
        "    print(directory_features)\n",
        "    length = extract_directory_length(url)\n",
        "    print(f\"Directory Length: {length}\")\n",
        "    file_features = extract_file_features(url)\n",
        "    print(file_features)\n",
        "    length = extract_file_length(url)\n",
        "    print(f\"File Length: {length}\")\n",
        "    params_features = extract_params_features(url)\n",
        "    print(params_features)\n",
        "    length = extract_params_length(url)\n",
        "    print(f\"Parameters Length: {length}\")\n",
        "    tld_in_params = tld_present_in_params(url)\n",
        "    print(f\"TLD Presence in Params: {tld_in_params}\")\n",
        "    param_count = count_params(url)\n",
        "    print(f\"Number of Parameters: {param_count}\")\n",
        "    has_email = email_in_url(url)\n",
        "    print(f\"Email in URL: {has_email}\")\n",
        "    print(f\"Response Time: {time_response} seconds\")\n",
        "    has_spf = has_spf_record(domain)\n",
        "    if has_spf:\n",
        "      print(f\"The domain {domain} has an SPF record.\")\n",
        "    else:\n",
        "      print(f\"The domain {domain} does not have an SPF record.\")\n",
        "    asn_info = get_asn_info(ip_address_to_check)\n",
        "    print(f\"The ASN for {ip_address_to_check} is: {asn_info}\")\n",
        "    activation_time, expiration_time = get_domain_dates(domain)\n",
        "    if activation_time is not None and expiration_time is not None:\n",
        "      print(f\"Activation time for {domain}: {activation_time} days\")\n",
        "      print(f\"Expiration time for {domain}: {expiration_time} days\")\n",
        "    else:\n",
        "      print(f\"Failed to retrieve activation and expiration times for {domain}\")\n",
        "    qty_ips = get_qty_resolved_ips(domain)\n",
        "    qty_ns = get_qty_nameservers(domain)\n",
        "    qty_mx = get_qty_mx_servers(domain)\n",
        "    print(f\"Quantity of resolved IPs for {domain}: {qty_ips}\")\n",
        "    print(f\"Quantity of name servers for {domain}: {qty_ns}\")\n",
        "    print(f\"Quantity of MX servers for {domain}: {qty_mx}\")\n",
        "    ttl = get_hostname_ttl(hostname)\n",
        "    if ttl is not None:\n",
        "      print(f\"TTL value for {hostname}: {ttl} seconds\")\n",
        "    else:\n",
        "      print(f\"Failed to retrieve TTL value for {hostname}\")\n",
        "    redirect_count = get_redirect_count(url)\n",
        "    print(f\"Number of redirects for {url}: {redirect_count}\")\n",
        "    url_indexed = check_url_indexing(url)\n",
        "    if url_indexed:\n",
        "      print(f\"The URL {url} is indexed on Google.\")\n",
        "    else:\n",
        "      print(f\"The URL {url} is not indexed on Google.\")\n",
        "    domain_indexed = check_domain_indexing(domain)\n",
        "    if domain_indexed:\n",
        "      print(f\"The domain {domain} is indexed on Google.\")\n",
        "    else:\n",
        "      print(f\"The domain {domain} is not indexed on Google.\")\n",
        "      print(f\"Is '{url}' a shortened URL? {is_url_shortened(url)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "aPldfIzvoRYj",
        "outputId": "0cf44f39-3ea8-4bc7-957a-5fe024b30c67"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://www.nitk.ac.in/\n",
            "{'dot': 3, 'hyphen': 0, 'underscore': 0, 'slash': 3, 'question_mark': 0, 'equal': 0, 'at': 0, 'ampersand': 0, 'exclamation': 0, 'space': 0, 'tilde': 0, 'comma': 0, 'plus': 0, 'asterisk': 0, 'hashtag': 0, 'dollar': 0, 'percent': 0}\n",
            "TLD Length: 5\n",
            "URL Length: 23\n",
            "{'dot_domain': 3, 'hyphen_domain': 0, 'underscore_domain': 0, 'slash_domain': 0, 'questionmark_domain': 0, 'equal_domain': 0, 'at_domain': 0, 'and_domain': 0, 'exclamation_domain': 0, 'space_domain': 0, 'tilde_domain': 0, 'comma_domain': 0, 'plus_domain': 0, 'asterisk_domain': 0, 'hashtag_domain': 0, 'dollar_domain': 0, 'percent_domain': 0, 'vowels_domain': 3}\n",
            "Domain Length: 14\n",
            "{'domain_in_ip': False, 'is_ip_address': True, 'ip_length': 13, 'ip': '218.248.46.85'}\n",
            "{'server_in_domain': False, 'client_in_domain': False}\n",
            "{'dot_directory': 0, 'hyphen_directory': 0, 'underscore_directory': 0, 'slash_directory': 1, 'questionmark_directory': 0, 'equal_directory': 0, 'at_directory': 0, 'and_directory': 0, 'exclamation_directory': 0, 'space_directory': 0, 'tilde_directory': 0, 'comma_directory': 0, 'plus_directory': 0, 'asterisk_directory': 0, 'hashtag_directory': 0, 'dollar_directory': 0, 'percent_directory': 0}\n",
            "Directory Length: 1\n",
            "{'dot_file': 0, 'hyphen_file': 0, 'underscore_file': 0, 'slash_file': 0, 'questionmark_file': 0, 'equal_file': 0, 'at_file': 0, 'and_file': 0, 'exclamation_file': 0, 'space_file': 0, 'tilde_file': 0, 'comma_file': 0, 'plus_file': 0, 'asterisk_file': 0, 'hashtag_file': 0, 'dollar_file': 0, 'percent_file': 0}\n",
            "File Length: 0\n",
            "{'dot_params': 0, 'hyphen_params': 0, 'underscore_params': 0, 'slash_params': 0, 'questionmark_params': 0, 'equal_params': 0, 'at_params': 0, 'and_params': 0, 'exclamation_params': 0, 'space_params': 0, 'tilde_params': 0, 'comma_params': 0, 'plus_params': 0, 'asterisk_params': 0, 'hashtag_params': 0, 'dollar_params': 0, 'percent_params': 0}\n",
            "Parameters Length: 0\n",
            "TLD Presence in Params: False\n",
            "Number of Parameters: 0\n",
            "Email in URL: False\n",
            "Response Time: <function time_response at 0x77ff63d6f5b0> seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a7f668e13651>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Email in URL: {has_email}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response Time: {time_response} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mhas_spf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_spf_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_spf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The domain {domain} has an SPF record.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'domain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(extracted_features)"
      ],
      "metadata": {
        "id": "7rbhcljdly_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "CH5HWiwQl2Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_csv(data, filename):\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['Domain','DomainLength','NumSubdomains', 'Path', 'PathLength', 'NumPathSegments', 'NumDash','NumDashInHostname','AtSymbol',\n",
        "                      'TildeSymbol','NumUnderscore','NumPercent','NumQueryComponents', 'NumAmpersand', 'NumHash','NumNumericChars','NoHttps',\n",
        "                      'RandomString','IpAddress', 'DomainInSubdomains','DomainInPaths', 'HttpsInHostname','HostnameLength','PathLength'\n",
        "                       'QueryLength',' DoubleSlashInPath',' NumSensitiveWords',' EmbeddedBrandName','PctExtHyperlinks',' PctExtResourceUrls',' ExtFavicon'\n",
        "                      'InsecureForms','RelativeFormAction','ExtFormAction','AbnormalFormAction','PctNullSelfRedirectHyperlinks'\n",
        "                      ,'FrequentDomainNameMismatch','FakeLinkInStatusBar','RightClickDisabled','PopUpWindow','SubmitInfoToEmail','IframeOrFrame'\n",
        "                      ,'MissingTitle','ImagesOnlyInForm','SubdomainLevelRT','UrlLengthRT','PctExtResourceUrlsRT','AbnormalExtFormActionR'\n",
        "                      ,'ExtMetaScriptLinkRT','PctExtNullSelfRedirectHyperlinksRT' ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)"
      ],
      "metadata": {
        "id": "J5GfAQAJ9iDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filename = 'url_features.csv'\n",
        "save_to_csv(extracted_features, csv_filename)\n",
        "print(f\"Features saved to '{csv_filename}'\")\n",
        "files.download(csv_filename)"
      ],
      "metadata": {
        "id": "8h1PeBEP_CnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}